{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encoder_inputs, decoder_inputs, decoder_targets):\n",
    "        self.encoder_inputs = encoder_inputs\n",
    "        self.decoder_inputs = decoder_inputs\n",
    "        self.decoder_targets = decoder_targets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"encoder_input_ids\" : self.encoder_inputs['input_ids'][idx], \n",
    "                \"encoder_attention_mask\" : self.encoder_inputs['attention_mask'][idx],\n",
    "                \"decoder_input_ids\" : self.decoder_inputs['input_ids'][idx],\n",
    "                \"decoder_input_attention_mask\" : self.decoder_inputs['attention_mask'][idx],\n",
    "                \"decoder_target_ids\" : self.decoder_targets['input_ids'][idx]}\n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inputs['input_ids'])\n",
    "    \n",
    "class Dataloader(pl.LightningDataModule):\n",
    "    def __init__(self, model_name, batch_size, shuffle, train_path, val_path, test_path, predict_path):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.train_path = train_path\n",
    "        self.val_path = val_path\n",
    "        self.test_path = test_path\n",
    "        self.predict_path = predict_path\n",
    "\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        special_tokens_dict = {'additional_special_tokens': ['[BOS]', '[SEP]']}\n",
    "        self.tokenizer.add_special_tokens(special_tokens_dict)\n",
    "        self.tokenizer.add_special_tokens({'bos_token': '<s>'})\n",
    "\n",
    "    def tokenizing(self, series, max_len):\n",
    "        tokens = self.tokenizer(series.tolist(), padding='max_length', max_length=max_len ,return_tensors=\"pt\", truncation=True)\n",
    "        return tokens # input_ids, attention_mask\n",
    "\n",
    "    def preprocessing(self,dataframe):\n",
    "        # session_dialog_add_special_tokens\n",
    "        dataframe['session_dialog'] = dataframe['session_dialog'].apply(lambda x: '[BOS] ' + ' [SEP] '.join(eval(x))+ ' </s>') # ['A','B','C'] -> '[BOS] A [SEP] B [SEP] C [SEP] </s>'\n",
    "        dataframe['session_persona'] = dataframe['session_persona'].apply(lambda x: '<s> '+','.join(eval(x)).replace('.','')+'.'+' </s>') # ['A.','B.','C.'] -> 'A,B,C.'\n",
    "        dataframe['session_persona_target'] =  dataframe['session_persona'].apply(lambda x: x[4:]) # <s> 제외\n",
    "\n",
    "        # tokenizing\n",
    "        encoder_inputs = self.tokenizing(dataframe['session_dialog'], max_len=500)\n",
    "        decoder_inputs = self.tokenizing(dataframe['session_persona'], max_len=200)\n",
    "        decoder_targets = self.tokenizing(dataframe['session_persona_target'], max_len=200)\n",
    "\n",
    "        return encoder_inputs, decoder_inputs, decoder_targets\n",
    "\n",
    "    def setup(self, stage='fit'):\n",
    "        if stage == 'fit':\n",
    "            train_df = pd.read_csv(self.train_path)\n",
    "            val_df = pd.read_csv(self.val_path)\n",
    "\n",
    "            train_encoder_inputs, train_decoder_inputs, train_decoder_targets = self.preprocessing(train_df)\n",
    "            val_encoder_inputs, val_decoder_inputs, val_decoder_targets  = self.preprocessing(val_df)\n",
    "\n",
    "            self.train_dataset = Dataset(train_encoder_inputs, train_decoder_inputs, train_decoder_targets)\n",
    "            self.val_dataset = Dataset(val_encoder_inputs, val_decoder_inputs, val_decoder_targets)\n",
    "        else:\n",
    "            test_df = pd.read_csv(self.test_path)\n",
    "            predict_df = pd.read_csv(self.predict_path)\n",
    "\n",
    "            test_encoder_inputs, test_decoder_inputs, test_decoder_targets= self.preprocessing(test_df)\n",
    "            predict_encoder_inputs, predict_decoder_inputs, perdict_decoder_targets = self.preprocessing(predict_df)\n",
    "\n",
    "            self.test_dataset = Dataset(test_encoder_inputs, test_decoder_inputs, test_decoder_targets)\n",
    "            self.predict_dataset = Dataset(predict_encoder_inputs, predict_decoder_inputs, perdict_decoder_targets)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset, batch_size=self.batch_size)\n",
    "\n",
    "config = {\"model_name\": 'gogamza/kobart-base-v2',\n",
    "              \"model_detail\" : \"kobart-baeline\",\n",
    "\n",
    "              \"batch_size\": 16, \n",
    "              \"shuffle\":True,\n",
    "              \"learning_rate\":1e-5,\n",
    "              \"epoch\": 10,\n",
    "\n",
    "              \"train_path\":'./data/train/train.csv', \n",
    "              \"dev_path\":'./data/val/validation.csv',\n",
    "              \"test_path\":'./data/val/validation.csv', \n",
    "              \"predict_path\":'./data/val/validation_csv',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "dataloader = Dataloader(config['model_name'], config['batch_size'], config['shuffle'], config['train_path'], config['dev_path'], config['test_path'], config['predict_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import re\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, model_name, lr, tokenizer):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = transformers.BartForConditionalGeneration.from_pretrained(model_name, cache_dir='./model')\n",
    "        self.model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "        self.model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lr = lr\n",
    "\n",
    "        self.loss = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "\n",
    "    def compute_rouge_score(self, logits, target) -> dict:\n",
    "        # logits : (batch_size, decoder_max_len, vocab_size)\n",
    "        # target : (batch_size, decoder_max_len)\n",
    "        rouge = Rouge()\n",
    "        \n",
    "        pred_strings = []\n",
    "        target_strings = []\n",
    "\n",
    "        pred_ids = torch.argmax(logits, dim=-1) # (batch_size, decoder_max_len)\n",
    "        for batch in range(pred_ids.shape[0]):\n",
    "            pred_string = re.findall(r'^.*(?=<\\/s>)',dataloader.tokenizer.decode(pred_ids[batch])) # truncate until </s>\n",
    "            if pred_string:\n",
    "                pred_string = pred_string[0].strip() if pred_string[0] else ' '\n",
    "            else:\n",
    "                pred_string = ' '\n",
    "             \n",
    "            target_string = self.tokenizer.decode(target[batch], skip_special_tokens=True)\n",
    "            pred_strings.append(pred_string)\n",
    "            target_strings.append(target_string)\n",
    "\n",
    "        \n",
    "        scores = rouge.get_scores(pred_strings, target_strings, avg=True)\n",
    "        # f1, precision, recall\n",
    "        # {'rouge-1': {'f': .., 'p': .., 'r': ..}, \n",
    "        # 'rouge-2': {'f': .., 'p': .., 'r': ..}, \n",
    "        # 'rouge-l': {'f': .., 'p': .., 'r': ..}}\n",
    "        \n",
    "        return scores \n",
    "\n",
    "    def compute_bleu_score(self, logits, target) -> float:\n",
    "        # logits : (batch_size, decoder_max_len, vocab_size)\n",
    "        # target : (batch_size, decoder_max_len)\n",
    "        total_bleu_score = 0\n",
    "\n",
    "        pred_ids = torch.argmax(logits, dim=-1)\n",
    "        for batch in range(pred_ids.shape[0]):\n",
    "            pred_string = re.findall(r'^.*(?=<\\/s>)',dataloader.tokenizer.decode(pred_ids[batch])) # truncate until </s>\n",
    "            if pred_string:\n",
    "                pred_string = pred_string[0].strip() if pred_string[0] else ' '\n",
    "            else:\n",
    "                pred_string = ' '\n",
    "            \n",
    "            target_string = self.tokenizer.decode(target[batch], skip_special_tokens=True).strip()\n",
    "            \n",
    "            total_bleu_score += sentence_bleu(target_string, pred_string, weights=(1, 0, 0, 0))\n",
    "\n",
    "        return total_bleu_score / pred_ids.shape[0]\n",
    "\n",
    "    def forward(self, **x):\n",
    "        '''\n",
    "        x = {\"encoder_input_ids\" : (batch_size, encoder_max_len),\n",
    "             \"encoder_attention_mask\" : (batch_size, encoder_max_len),\n",
    "             \"decoder_input_ids\" : (batch_size, decoder_max_len), # target 역할도 수행\n",
    "             \"decoder_input_attention_mask\" : (batch_size, decoder_max_len)}\n",
    "        '''\n",
    "\n",
    "        outputs = self.model(input_ids=x['encoder_input_ids'], attention_mask=x['encoder_attention_mask'], \n",
    "                            decoder_input_ids=x['decoder_input_ids'], decoder_attention_mask=x['decoder_input_attention_mask'])\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        outputs = self(**batch) # (batch_size, decoder_max_len, vocab_size)\n",
    "        loss = self.loss(outputs.logits.view(-1, outputs.logits.shape[-1]), batch['decoder_target_ids'].view(-1)) # (batch_size*decoder_max_len, vocab_size), (batch_size*decoder_max_len)\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        rouge_score = self.compute_rouge_score(outputs.logits, batch['decoder_target_ids'])\n",
    "        bleu_score = self.compute_bleu_score(outputs.logits, batch['decoder_target_ids'])\n",
    "\n",
    "        self.log_dict({\"rouge-1-recall\" : round(rouge_score['rouge-1']['r'],3),\n",
    "                       \"rouge-1-precision\" : round(rouge_score['rouge-1']['p'],3),\n",
    "                       \"rouge-1-f1\" : round(rouge_score['rouge-1']['f'],3)})\n",
    "        self.log_dict({\"rouge-2-recall\" : round(rouge_score['rouge-2']['r'],3),\n",
    "                        \"rouge-2-precision\" : round(rouge_score['rouge-2']['p'],3),\n",
    "                        \"rouge-2-f1\" : round(rouge_score['rouge-2']['f'],3)})\n",
    "        self.log_dict({\"rouge-l-recall\" : round(rouge_score['rouge-l']['r'],3),\n",
    "                        \"rouge-l-precision\" : round(rouge_score['rouge-l']['p'],3),\n",
    "                        \"rouge-l-f1\" : round(rouge_score['rouge-l']['f'],3)})\n",
    "        self.log_dict({\"bleu_avg\" : round(bleu_score,3)})\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        outputs = self(**batch)\n",
    "        loss = self.loss(outputs.logits.view(-1, outputs.logits.shape[-1]), batch['decoder_input_ids'].view(-1))\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "        rouge_score = self.compute_rouge_score(outputs.logits, batch['decoder_target_ids'])\n",
    "        bleu_score = self.compute_bleu_score(outputs.logits, batch['decoder_target_ids'])\n",
    "\n",
    "        self.log_dict({\"val_rouge-1-recall\" : round(rouge_score['rouge-1']['r'],3),\n",
    "                       \"val_rouge-1-precision\" : round(rouge_score['rouge-1']['p'],3),\n",
    "                       \"val_rouge-1-f1\" : round(rouge_score['rouge-1']['f'],3)})\n",
    "        self.log_dict({\"val_rouge-2-recall\" : round(rouge_score['rouge-2']['r'],3),\n",
    "                        \"val_rouge-2-precision\" : round(rouge_score['rouge-2']['p'],3),\n",
    "                        \"val_rouge-2-f1\" : round(rouge_score['rouge-2']['f'],3)})\n",
    "        self.log_dict({\"val_rouge-l-recall\" : round(rouge_score['rouge-l']['r'],3),\n",
    "                        \"val_rouge-l-precision\" : round(rouge_score['rouge-l']['p'],3),\n",
    "                        \"val_rouge-l-f1\" : round(rouge_score['rouge-l']['f'],3)})\n",
    "        self.log_dict({\"val_bleu_avg\" : round(bleu_score,3)})\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "            \n",
    "        outputs = self(**batch)\n",
    "        # loss = self.loss(logits.view(-1, logits.shape[-1]), batch['decoder_input_ids'].view(-1))\n",
    "    \n",
    "        return outputs.loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "\n",
    "        outputs = self(**batch)\n",
    "        return outputs.logits\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model = Model.load_from_checkpoint('./checkpoints/gogamza/kobart-base-v2kobart-baeline-rouge-bleu-by-val_bleu_avg-v1.ckpt', model_name=config[\"model_name\"], lr=config[\"learning_rate\"], tokenizer=dataloader.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation_predict.csv라는 이름으로 valdiation dataset에 대한 학습된 모델의 예측 결과를 저장\n",
    "- column은 'id', 'session_dialog', 'predict_persona', 'session_persona'로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation dataset 불러오기\n",
    "\n",
    "val_df = pd.read_csv(config['dev_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>session_dialog</th>\n",
       "      <th>session_persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K2-07923-CL20177-CP22499-03-01-S2.json</td>\n",
       "      <td>['벌써 6일이 지났네요. 그동안 어떻게 지내셨어요?', '운동 너무 좋죠! 저는 ...</td>\n",
       "      <td>['나는 중고차를 알아보려 한다.', '나는 첫차로 중고차를 사려고 한다.', '나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K2-20311-CL31505-CP51040-08-08-S2.json</td>\n",
       "      <td>['안녕하세요 저는 30대 여성입니다.', '반갑습니다. 저는 동해에 거주해서 바닷...</td>\n",
       "      <td>['나는 30대 여성이다.', '나는 물 멍을 좋아한다. 나의 거주지는 동해이다.'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K2-26781-CL20066-CP22442-12-09-S2.json</td>\n",
       "      <td>['오~ 재밌겠당. 어디로 캠핑 가셨는데요?', '재밌겠당.ㅎ 왜 놀러가서 화가 나...</td>\n",
       "      <td>['나는 글램핑을 안 해봤다.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K2-25258-CL31722-CP52004-19-07-S2.json</td>\n",
       "      <td>['안녕하세요 저는 30대 여성입니다.', '우와 멋져요~ 저는 사학과 전공했어요~...</td>\n",
       "      <td>['나는 30대 여성이다', '나는 사학과를 전공했다', '나는 주말에 청소를 하고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K2-00603-CL00969-CP04174-14-04-S2.json</td>\n",
       "      <td>['안녕하세요. 저는 27살 경기도에 사는 남자입니다.', '오늘 1년만에 가족을 ...</td>\n",
       "      <td>['나는 27살 경기도에 사는 남자이다.', '1년 만에 가족을 만났다. 나는 바빠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8259</th>\n",
       "      <td>K2-32236-CL00289-CP01114-20-05-S2.json</td>\n",
       "      <td>['20대 남자입니다! 반가워요 ㅎㅎ.', '황야의 아들들 이란 영화 아시나요? 제...</td>\n",
       "      <td>['나는 20대 남성이다.', '나는 황야의 아들들 이란 영화를 좋아한다.', '내...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8260</th>\n",
       "      <td>K2-23009-CL13163-CP61924-08-09-S2.json</td>\n",
       "      <td>['안녕하세요, 벌써 시간이 이렇게 지났네요! 이틀만이죠?', '네, 남녀공학인 학...</td>\n",
       "      <td>['나는 남녀공학 학교에 다녀서 이성 친구가 있다', '나는 얼른 자라서 결혼하고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8261</th>\n",
       "      <td>K2-28946-CL20593-CP22448-02-10-S2.json</td>\n",
       "      <td>['안녕하세요? 1 시간 만인가요? 아까 대화 즐거웠어요.', '네. 근데 1 시간...</td>\n",
       "      <td>['나는 상대방에게 친근감을 느꼈다.', '요즘에는 주거 환경을 중요하게 생각한다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8262</th>\n",
       "      <td>K2-34376-CL21457-CP22584-17-01-S2.json</td>\n",
       "      <td>['반갑습니다. 저는 화학부 전공하는 20대 여대생입니다.', '맞아요. 전 이과 ...</td>\n",
       "      <td>['나는 20대 여자이다. 나는 화학부 전공이다. 나는 대학생이다.', '나는 이과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>K2-23538-CL20461-CP22251-11-03-S2.json</td>\n",
       "      <td>['반가워요. 저는 20대 여자입니다.', '전 사회학과를 전공하고있어요. 딱딱한가...</td>\n",
       "      <td>['나는 20대 여자이다.', '나는 사회학과 전공이다.', '나는 첼로 연주를 자...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id  \\\n",
       "0     K2-07923-CL20177-CP22499-03-01-S2.json   \n",
       "1     K2-20311-CL31505-CP51040-08-08-S2.json   \n",
       "2     K2-26781-CL20066-CP22442-12-09-S2.json   \n",
       "3     K2-25258-CL31722-CP52004-19-07-S2.json   \n",
       "4     K2-00603-CL00969-CP04174-14-04-S2.json   \n",
       "...                                      ...   \n",
       "8259  K2-32236-CL00289-CP01114-20-05-S2.json   \n",
       "8260  K2-23009-CL13163-CP61924-08-09-S2.json   \n",
       "8261  K2-28946-CL20593-CP22448-02-10-S2.json   \n",
       "8262  K2-34376-CL21457-CP22584-17-01-S2.json   \n",
       "8263  K2-23538-CL20461-CP22251-11-03-S2.json   \n",
       "\n",
       "                                         session_dialog  \\\n",
       "0     ['벌써 6일이 지났네요. 그동안 어떻게 지내셨어요?', '운동 너무 좋죠! 저는 ...   \n",
       "1     ['안녕하세요 저는 30대 여성입니다.', '반갑습니다. 저는 동해에 거주해서 바닷...   \n",
       "2     ['오~ 재밌겠당. 어디로 캠핑 가셨는데요?', '재밌겠당.ㅎ 왜 놀러가서 화가 나...   \n",
       "3     ['안녕하세요 저는 30대 여성입니다.', '우와 멋져요~ 저는 사학과 전공했어요~...   \n",
       "4     ['안녕하세요. 저는 27살 경기도에 사는 남자입니다.', '오늘 1년만에 가족을 ...   \n",
       "...                                                 ...   \n",
       "8259  ['20대 남자입니다! 반가워요 ㅎㅎ.', '황야의 아들들 이란 영화 아시나요? 제...   \n",
       "8260  ['안녕하세요, 벌써 시간이 이렇게 지났네요! 이틀만이죠?', '네, 남녀공학인 학...   \n",
       "8261  ['안녕하세요? 1 시간 만인가요? 아까 대화 즐거웠어요.', '네. 근데 1 시간...   \n",
       "8262  ['반갑습니다. 저는 화학부 전공하는 20대 여대생입니다.', '맞아요. 전 이과 ...   \n",
       "8263  ['반가워요. 저는 20대 여자입니다.', '전 사회학과를 전공하고있어요. 딱딱한가...   \n",
       "\n",
       "                                        session_persona  \n",
       "0     ['나는 중고차를 알아보려 한다.', '나는 첫차로 중고차를 사려고 한다.', '나...  \n",
       "1     ['나는 30대 여성이다.', '나는 물 멍을 좋아한다. 나의 거주지는 동해이다.'...  \n",
       "2                                    ['나는 글램핑을 안 해봤다.']  \n",
       "3     ['나는 30대 여성이다', '나는 사학과를 전공했다', '나는 주말에 청소를 하고...  \n",
       "4     ['나는 27살 경기도에 사는 남자이다.', '1년 만에 가족을 만났다. 나는 바빠...  \n",
       "...                                                 ...  \n",
       "8259  ['나는 20대 남성이다.', '나는 황야의 아들들 이란 영화를 좋아한다.', '내...  \n",
       "8260  ['나는 남녀공학 학교에 다녀서 이성 친구가 있다', '나는 얼른 자라서 결혼하고 ...  \n",
       "8261  ['나는 상대방에게 친근감을 느꼈다.', '요즘에는 주거 환경을 중요하게 생각한다....  \n",
       "8262  ['나는 20대 여자이다. 나는 화학부 전공이다. 나는 대학생이다.', '나는 이과...  \n",
       "8263  ['나는 20대 여자이다.', '나는 사회학과 전공이다.', '나는 첼로 연주를 자...  \n",
       "\n",
       "[8264 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation dataset에 대해 예측값 생성 후 csv로 저장\n",
    "\n",
    "def predict_save_csv(model, dataloader, save_path):\n",
    "    predict_df = pd.DataFrame(columns=['predict_persona'])\n",
    "    val_dataloader=dataloader.val_dataloader()\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.model.generate(batch['encoder_input_ids'].to('cuda'), max_length=200, num_beams=4, early_stopping=True)\n",
    "            preds = [dataloader.tokenizer.decode(outputs[i], skip_special_tokens=True) for i in range(outputs.shape[0])]\n",
    "            chunk_df = pd.DataFrame({'predict_persona':preds})\n",
    "            predict_df = pd.concat([predict_df, chunk_df], ignore_index=True)\n",
    "    \n",
    "    validation_predict_df = pd.concat([val_df, predict_df], axis=1)\n",
    "    validation_predict_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517/517 [12:38<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "predict_save_csv(model, dataloader, './validation_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>session_dialog</th>\n",
       "      <th>session_persona</th>\n",
       "      <th>predict_persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K2-07923-CL20177-CP22499-03-01-S2.json</td>\n",
       "      <td>['벌써 6일이 지났네요. 그동안 어떻게 지내셨어요?', '운동 너무 좋죠! 저는 ...</td>\n",
       "      <td>['나는 중고차를 알아보려 한다.', '나는 첫차로 중고차를 사려고 한다.', '나...</td>\n",
       "      <td>나는 중고 중고차를 알아볼 것이다,나는 중고차가 부담스럽다,나는 가을에 음악을 듣는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K2-20311-CL31505-CP51040-08-08-S2.json</td>\n",
       "      <td>['안녕하세요 저는 30대 여성입니다.', '반갑습니다. 저는 동해에 거주해서 바닷...</td>\n",
       "      <td>['나는 30대 여성이다.', '나는 물 멍을 좋아한다. 나의 거주지는 동해이다.'...</td>\n",
       "      <td>나는 30대 여성이다,나는 동해에 거주한다,나는 가끔 만족스럽다,나는 단감을 자주 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K2-26781-CL20066-CP22442-12-09-S2.json</td>\n",
       "      <td>['오~ 재밌겠당. 어디로 캠핑 가셨는데요?', '재밌겠당.ㅎ 왜 놀러가서 화가 나...</td>\n",
       "      <td>['나는 글램핑을 안 해봤다.']</td>\n",
       "      <td>나는 글램핑을 해본 적이 없다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K2-25258-CL31722-CP52004-19-07-S2.json</td>\n",
       "      <td>['안녕하세요 저는 30대 여성입니다.', '우와 멋져요~ 저는 사학과 전공했어요~...</td>\n",
       "      <td>['나는 30대 여성이다', '나는 사학과를 전공했다', '나는 주말에 청소를 하고...</td>\n",
       "      <td>나는 30대 여성이다,나는 사학과 전공이다,나는 주말에 청소를 하고 치킨을 안 먹는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K2-00603-CL00969-CP04174-14-04-S2.json</td>\n",
       "      <td>['안녕하세요. 저는 27살 경기도에 사는 남자입니다.', '오늘 1년만에 가족을 ...</td>\n",
       "      <td>['나는 27살 경기도에 사는 남자이다.', '1년 만에 가족을 만났다. 나는 바빠...</td>\n",
       "      <td>나는 27살 경기도에 사는 남자이다,나는 가족과 1년 만에 만난다,나는 일식을 즐겨...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "0  K2-07923-CL20177-CP22499-03-01-S2.json   \n",
       "1  K2-20311-CL31505-CP51040-08-08-S2.json   \n",
       "2  K2-26781-CL20066-CP22442-12-09-S2.json   \n",
       "3  K2-25258-CL31722-CP52004-19-07-S2.json   \n",
       "4  K2-00603-CL00969-CP04174-14-04-S2.json   \n",
       "\n",
       "                                      session_dialog  \\\n",
       "0  ['벌써 6일이 지났네요. 그동안 어떻게 지내셨어요?', '운동 너무 좋죠! 저는 ...   \n",
       "1  ['안녕하세요 저는 30대 여성입니다.', '반갑습니다. 저는 동해에 거주해서 바닷...   \n",
       "2  ['오~ 재밌겠당. 어디로 캠핑 가셨는데요?', '재밌겠당.ㅎ 왜 놀러가서 화가 나...   \n",
       "3  ['안녕하세요 저는 30대 여성입니다.', '우와 멋져요~ 저는 사학과 전공했어요~...   \n",
       "4  ['안녕하세요. 저는 27살 경기도에 사는 남자입니다.', '오늘 1년만에 가족을 ...   \n",
       "\n",
       "                                     session_persona  \\\n",
       "0  ['나는 중고차를 알아보려 한다.', '나는 첫차로 중고차를 사려고 한다.', '나...   \n",
       "1  ['나는 30대 여성이다.', '나는 물 멍을 좋아한다. 나의 거주지는 동해이다.'...   \n",
       "2                                 ['나는 글램핑을 안 해봤다.']   \n",
       "3  ['나는 30대 여성이다', '나는 사학과를 전공했다', '나는 주말에 청소를 하고...   \n",
       "4  ['나는 27살 경기도에 사는 남자이다.', '1년 만에 가족을 만났다. 나는 바빠...   \n",
       "\n",
       "                                     predict_persona  \n",
       "0  나는 중고 중고차를 알아볼 것이다,나는 중고차가 부담스럽다,나는 가을에 음악을 듣는...  \n",
       "1  나는 30대 여성이다,나는 동해에 거주한다,나는 가끔 만족스럽다,나는 단감을 자주 ...  \n",
       "2                                 나는 글램핑을 해본 적이 없다.   \n",
       "3  나는 30대 여성이다,나는 사학과 전공이다,나는 주말에 청소를 하고 치킨을 안 먹는...  \n",
       "4  나는 27살 경기도에 사는 남자이다,나는 가족과 1년 만에 만난다,나는 일식을 즐겨...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predict_df = pd.read_csv('./validation_predict.csv')\n",
    "validation_predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persona_extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
